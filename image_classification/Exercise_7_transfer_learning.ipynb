{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - transfer learning",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmeng/deep_learning_code/blob/master/CNN/Exercise_7_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "45358f73-a44e-40c5-efe2-0fb807479441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "# include_top=False not including the top classification layer\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape = (150, 150, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet')\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-23 21:46:43--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   133MB/s    in 0.6s    \n",
            "\n",
            "2019-12-23 21:46:44 (133 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "e17a4d2d-c6da-4d91-a734-10357b56e1ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer(\"mixed7\")\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "7ea5cd70-caaa-4e42-9b21-fbad6692f2ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(inputs=pre_trained_model.inputs, outputs=x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = \"binary_crossentropy\", \n",
        "              metrics = [\"acc\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "a01b5da4-27c6-4a88-8883-829db2bd4a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-23 21:46:56--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.214.128, 2607:f8b0:4001:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.214.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  66.3MB/s    in 2.2s    \n",
            "\n",
            "2019-12-23 21:46:58 (66.3 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-12-23 21:46:59--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.197.128, 2607:f8b0:4001:c1b::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-12-23 21:46:59 (101 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRzIClQ9LOCI",
        "colab_type": "code",
        "outputId": "277a8f42-ee1c-4fff-d5fa-ea90db448b76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /tmp/training"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "horses\thumans\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "03ebe5b8-25e5-4a2d-f198-7c79337d8729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses'\n",
        "train_humans_dir = '/tmp/training/humans'\n",
        "validation_horses_dir = '/tmp/validation/horses'\n",
        "validation_humans_dir = '/tmp/validation/humans'\n",
        "\n",
        "train_horses_fnames = [ name for name in os.listdir(train_horses_dir)]\n",
        "train_humans_fnames = [ name for name in os.listdir(train_humans_dir)]\n",
        "validation_horses_fnames = [ name for name in os.listdir(validation_horses_dir)]\n",
        "validation_humans_fnames = [ name for name in os.listdir(validation_humans_dir)]\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "32dbcfdf-b315-4389-f5c5-2dbdfc8bd5f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, batch_size=20, class_mode='binary', target_size=(150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(\n",
        "    validation_dir, batch_size=20, class_mode='binary', target_size=(150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "fd99d526-385e-41c7-bea9-2096edd07e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    validation_data=validation_generator, \n",
        "    callbacks=[callbacks], \n",
        "    steps_per_epoch = 100,\n",
        "    validation_steps = 50,\n",
        "    verbose = 2,\n",
        "    epochs=100)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "100/100 - 28s - loss: 0.1746 - acc: 0.9260 - val_loss: 0.0050 - val_acc: 1.0000\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0887 - acc: 0.9683 - val_loss: 0.0809 - val_acc: 0.9777\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0370 - acc: 0.9852 - val_loss: 4.8177e-04 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0430 - acc: 0.9873 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0428 - acc: 0.9824 - val_loss: 0.0072 - val_acc: 0.9960\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0283 - acc: 0.9918 - val_loss: 0.0440 - val_acc: 0.9889\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0289 - acc: 0.9904 - val_loss: 0.1225 - val_acc: 0.9808\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0182 - acc: 0.9935 - val_loss: 0.0549 - val_acc: 0.9899\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0317 - acc: 0.9919 - val_loss: 0.0321 - val_acc: 0.9919\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0346 - acc: 0.9898 - val_loss: 0.0284 - val_acc: 0.9919\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0332 - acc: 0.9935 - val_loss: 0.2501 - val_acc: 0.9696\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0282 - acc: 0.9919 - val_loss: 0.2073 - val_acc: 0.9727\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0233 - acc: 0.9934 - val_loss: 0.1899 - val_acc: 0.9757\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0117 - acc: 0.9949 - val_loss: 0.5631 - val_acc: 0.9524\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0182 - acc: 0.9919 - val_loss: 0.6832 - val_acc: 0.9484\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0109 - acc: 0.9965 - val_loss: 0.4795 - val_acc: 0.9565\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0062 - acc: 0.9969 - val_loss: 0.3651 - val_acc: 0.9534\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0187 - acc: 0.9934 - val_loss: 0.7141 - val_acc: 0.9443\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0207 - acc: 0.9950 - val_loss: 0.2579 - val_acc: 0.9727\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0149 - acc: 0.9954 - val_loss: 0.4841 - val_acc: 0.9565\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0138 - acc: 0.9970 - val_loss: 0.2456 - val_acc: 0.9686\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0194 - acc: 0.9954 - val_loss: 0.4847 - val_acc: 0.9484\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0203 - acc: 0.9929 - val_loss: 0.7464 - val_acc: 0.9504\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0123 - acc: 0.9965 - val_loss: 0.7370 - val_acc: 0.9494\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0149 - acc: 0.9954 - val_loss: 0.5905 - val_acc: 0.9534\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0047 - acc: 0.9980 - val_loss: 0.9598 - val_acc: 0.9474\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0190 - acc: 0.9949 - val_loss: 0.4600 - val_acc: 0.9514\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0190 - acc: 0.9934 - val_loss: 0.1629 - val_acc: 0.9838\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0122 - acc: 0.9959 - val_loss: 0.3388 - val_acc: 0.9626\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0136 - acc: 0.9959 - val_loss: 1.0937 - val_acc: 0.9453\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0144 - acc: 0.9950 - val_loss: 0.7898 - val_acc: 0.9484\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0162 - acc: 0.9975 - val_loss: 0.4930 - val_acc: 0.9585\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0261 - acc: 0.9944 - val_loss: 0.9126 - val_acc: 0.9494\n",
            "Epoch 34/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0131 - acc: 0.9970 - val_loss: 0.5427 - val_acc: 0.9534\n",
            "Epoch 35/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0154 - acc: 0.9969 - val_loss: 0.1815 - val_acc: 0.9757\n",
            "Epoch 36/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0079 - acc: 0.9975 - val_loss: 0.4907 - val_acc: 0.9575\n",
            "Epoch 37/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0171 - acc: 0.9954 - val_loss: 0.5294 - val_acc: 0.9575\n",
            "Epoch 38/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0101 - acc: 0.9954 - val_loss: 0.8038 - val_acc: 0.9504\n",
            "Epoch 39/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0103 - acc: 0.9965 - val_loss: 0.9150 - val_acc: 0.9504\n",
            "Epoch 40/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0113 - acc: 0.9970 - val_loss: 1.0342 - val_acc: 0.9494\n",
            "Epoch 41/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0223 - acc: 0.9954 - val_loss: 0.9024 - val_acc: 0.9474\n",
            "Epoch 42/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0140 - acc: 0.9975 - val_loss: 1.2818 - val_acc: 0.9443\n",
            "Epoch 43/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0179 - acc: 0.9960 - val_loss: 0.8730 - val_acc: 0.9494\n",
            "Epoch 44/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0181 - acc: 0.9954 - val_loss: 1.0837 - val_acc: 0.9484\n",
            "Epoch 45/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0244 - acc: 0.9950 - val_loss: 1.6799 - val_acc: 0.9393\n",
            "Epoch 46/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0078 - acc: 0.9980 - val_loss: 1.2950 - val_acc: 0.9413\n",
            "Epoch 47/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0163 - acc: 0.9980 - val_loss: 1.3869 - val_acc: 0.9413\n",
            "Epoch 48/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0062 - acc: 0.9975 - val_loss: 1.2462 - val_acc: 0.9494\n",
            "Epoch 49/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0099 - acc: 0.9959 - val_loss: 1.0842 - val_acc: 0.9464\n",
            "Epoch 50/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0073 - acc: 0.9975 - val_loss: 1.0504 - val_acc: 0.9484\n",
            "Epoch 51/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0181 - acc: 0.9959 - val_loss: 0.8146 - val_acc: 0.9615\n",
            "Epoch 52/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0183 - acc: 0.9970 - val_loss: 0.7744 - val_acc: 0.9585\n",
            "Epoch 53/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0110 - acc: 0.9975 - val_loss: 0.9464 - val_acc: 0.9534\n",
            "Epoch 54/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0144 - acc: 0.9970 - val_loss: 1.3283 - val_acc: 0.9403\n",
            "Epoch 55/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0343 - acc: 0.9970 - val_loss: 1.1112 - val_acc: 0.9443\n",
            "Epoch 56/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0121 - acc: 0.9949 - val_loss: 1.1956 - val_acc: 0.9494\n",
            "Epoch 57/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0148 - acc: 0.9970 - val_loss: 1.7580 - val_acc: 0.9271\n",
            "Epoch 58/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0171 - acc: 0.9954 - val_loss: 1.4700 - val_acc: 0.9413\n",
            "Epoch 59/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0107 - acc: 0.9965 - val_loss: 1.2380 - val_acc: 0.9494\n",
            "Epoch 60/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0081 - acc: 0.9980 - val_loss: 1.6585 - val_acc: 0.9271\n",
            "Epoch 61/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0091 - acc: 0.9980 - val_loss: 1.6913 - val_acc: 0.9261\n",
            "Epoch 62/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0122 - acc: 0.9965 - val_loss: 0.8944 - val_acc: 0.9575\n",
            "Epoch 63/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0226 - acc: 0.9949 - val_loss: 1.2507 - val_acc: 0.9494\n",
            "Epoch 64/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0184 - acc: 0.9985 - val_loss: 0.9916 - val_acc: 0.9534\n",
            "Epoch 65/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0114 - acc: 0.9959 - val_loss: 0.6226 - val_acc: 0.9666\n",
            "Epoch 66/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0027 - acc: 0.9990 - val_loss: 0.9201 - val_acc: 0.9565\n",
            "Epoch 67/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0186 - acc: 0.9959 - val_loss: 0.8871 - val_acc: 0.9534\n",
            "Epoch 68/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0149 - acc: 0.9965 - val_loss: 0.7746 - val_acc: 0.9605\n",
            "Epoch 69/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0065 - acc: 0.9985 - val_loss: 0.8930 - val_acc: 0.9545\n",
            "Epoch 70/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0093 - acc: 0.9990 - val_loss: 1.1645 - val_acc: 0.9494\n",
            "Epoch 71/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0182 - acc: 0.9975 - val_loss: 0.8062 - val_acc: 0.9636\n",
            "Epoch 72/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0106 - acc: 0.9970 - val_loss: 0.9203 - val_acc: 0.9545\n",
            "Epoch 73/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0099 - acc: 0.9970 - val_loss: 0.7862 - val_acc: 0.9646\n",
            "Epoch 74/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0081 - acc: 0.9975 - val_loss: 0.9857 - val_acc: 0.9555\n",
            "Epoch 75/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0072 - acc: 0.9980 - val_loss: 0.9860 - val_acc: 0.9575\n",
            "Epoch 76/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0095 - acc: 0.9970 - val_loss: 0.7799 - val_acc: 0.9656\n",
            "Epoch 77/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0114 - acc: 0.9980 - val_loss: 1.3416 - val_acc: 0.9453\n",
            "Epoch 78/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0150 - acc: 0.9975 - val_loss: 1.1065 - val_acc: 0.9443\n",
            "Epoch 79/100\n",
            "Epoch 1/100\n",
            "100/100 - 22s - loss: 0.0115 - acc: 0.9970 - val_loss: 0.9798 - val_acc: 0.9524\n",
            "Epoch 80/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0319 - acc: 0.9944 - val_loss: 0.9404 - val_acc: 0.9565\n",
            "Epoch 81/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0039 - acc: 0.9990 - val_loss: 0.9888 - val_acc: 0.9443\n",
            "Epoch 82/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0147 - acc: 0.9959 - val_loss: 1.0847 - val_acc: 0.9464\n",
            "Epoch 83/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0113 - acc: 0.9965 - val_loss: 1.1961 - val_acc: 0.9453\n",
            "Epoch 84/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0091 - acc: 0.9975 - val_loss: 0.8021 - val_acc: 0.9686\n",
            "Epoch 85/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0079 - acc: 0.9980 - val_loss: 0.8144 - val_acc: 0.9585\n",
            "Epoch 86/100\n",
            "Epoch 1/100\n",
            "100/100 - 23s - loss: 0.0077 - acc: 0.9980 - val_loss: 1.2731 - val_acc: 0.9464\n",
            "Epoch 87/100\n",
            "Epoch 1/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 23s - loss: 0.0051 - acc: 0.9995 - val_loss: 1.3558 - val_acc: 0.9443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "1beaef58-94ee-4700-b122-07f2905a2d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydd3gU1frHv28SINQECUiJUoMQFCIg\nwg8VBESwoaAXvWK9yrWgYserXntvFPtVVNQreoMoKl6livUKSg8CoSihSUsCoaTs+/vjnZOdnczs\nzibbcz7Ps8/uzpyZObM78z3vvOc97yFmhkaj0WgSl6RoV0Cj0Wg04UULvUaj0SQ4Wug1Go0mwdFC\nr9FoNAmOFnqNRqNJcLTQazQaTYKjhb4WQkTJRHSAiI4NZdloQkSdiCjkscJENISINpu+ryWiU92U\nrcax3iCif1R3e43GiZRoV0ATGCI6YPraAMARABXG978z8/vB7I+ZKwA0CnXZ2gAzHxeK/RDRNQDG\nMPNA076vCcW+NRorWujjAGauFFrDYryGmec6lSeiFGYuj0TdNJpA6Osx+mjXTQJARI8S0YdE9AER\n7Qcwhoj6EdFPRFRIRNuJaDIR1THKpxARE1E74/t7xvoviWg/Ef1IRO2DLWusH05E64ioiIimENH3\nRHSlQ73d1PHvRJRPRPuIaLJp22QieoGI9hDRRgDD/Pw+9xLRdMuyl4joeePzNUS0xjifDYa17bSv\nAiIaaHxuQETvGnVbDaCXpex9RLTR2O9qIjrPWH4CgBcBnGq4xXabftsHTdtfZ5z7HiL6hIhauflt\ngvmdVX2IaC4R7SWiHUR0l+k49xu/STERLSGi1nZuMiL6Tv3Pxu+5yDjOXgD3EVEWES0wjrHb+N3S\nTNu3Nc5xl7F+EhGlGnXuairXiogOElEzp/PV2MDM+hVHLwCbAQyxLHsUQCmAcyGNd30AJwE4GfLU\n1gHAOgDjjPIpABhAO+P7ewB2A+gNoA6ADwG8V42yLQDsBzDCWHcbgDIAVzqci5s6fgogDUA7AHvV\nuQMYB2A1gEwAzQAsksvZ9jgdABwA0NC07z8B9Da+n2uUIQCDABwC0N1YNwTAZtO+CgAMND4/C2Ah\ngKYA2gLIs5T9C4BWxn/yV6MORxvrrgGw0FLP9wA8aHweatQxB0AqgJcBzHfz2wT5O6cB2AngFgD1\nADQB0MdYdw+A5QCyjHPIAXAUgE7W3xrAd+p/Ns6tHMD1AJIh12NnAIMB1DWuk+8BPGs6n1XG79nQ\nKN/fWPc6gMdMx7kdwMxo34fx9op6BfQryD/MWejnB9juDgD/MT7biferprLnAVhVjbJXA/jWtI4A\nbIeD0LusY1/T+o8B3GF8XgRxYal1Z1nFx7LvnwD81fg8HMBaP2U/B3Cj8dmf0P9h/i8A3GAua7Pf\nVQDONj4HEvp3ADxuWtcE0i+TGei3CfJ3vgzAYodyG1R9LcvdCP3GAHW4UB0XwKkAdgBItinXH8Am\nAGR8XwZgZKjvq0R/addN4rDF/IWIuhDRF8ajeDGAhwFk+Nl+h+nzQfjvgHUq29pcD5Y7s8BpJy7r\n6OpYAH73U18A+DeAS4zPfzW+q3qcQ0T/M9wKhRBr2t9vpWjlrw5EdCURLTfcD4UAurjcLyDnV7k/\nZi4GsA9AG1MZV/9ZgN/5GIig2+FvXSCs12NLIvqIiLYadXjbUofNLB3/PjDz95Cng1OI6HgAxwL4\nopp1qrVooU8crKGFr0EsyE7M3ATAPyEWdjjZDrE4AQBERPAVJis1qeN2iEAoAoV/fgRgCBG1gbiW\n/m3UsT6AXABPQNwq6QC+dlmPHU51IKIOAF6BuC+aGfv9zbTfQKGg2yDuILW/xhAX0VYX9bLi73fe\nAqCjw3ZO60qMOjUwLWtpKWM9v6cg0WInGHW40lKHtkSU7FCPaQDGQJ4+PmLmIw7lNA5ooU9cGgMo\nAlBidGb9PQLH/BxATyI6l4hSIH7f5mGq40cAxhNRG6Nj7m5/hZl5B8S98DbEbbPeWFUP4jfeBaCC\niM6B+JLd1uEfRJROMs5gnGldI4jY7YK0eddCLHrFTgCZ5k5RCx8A+BsRdSeiepCG6FtmdnxC8oO/\n33kWgGOJaBwR1SOiJkTUx1j3BoBHiagjCTlEdBSkgdsB6fRPJqKxMDVKfupQAqCIiI6BuI8UPwLY\nA+Bxkg7u+kTU37T+XYir568Q0dcEiRb6xOV2AFdAOkdfg3SahhVm3glgNIDnITduRwBLIZZcqOv4\nCoB5AFYCWAyxygPxb4jPvdJtw8yFAG4FMBPSoXkhpMFywwOQJ4vNAL6ESYSYeQWAKQB+NsocB+B/\npm3nAFgPYCcRmV0wavv/QlwsM43tjwVwqct6WXH8nZm5CMAZAEZBGp91AAYYq58B8Ankdy6GdIym\nGi65awH8A9Ix38lybnY8AKAPpMGZBWCGqQ7lAM4B0BVi3f8B+R/U+s2Q//kIM/8Q5Llr4O3g0GhC\njvEovg3Ahcz8bbTro4lfiGgapIP3wWjXJR7RA6Y0IYWIhkEiXA5BwvPKIFatRlMtjP6OEQBOiHZd\n4hXtutGEmlMAbIT4ps8EcIHuPNNUFyJ6AhLL/zgz/xHt+sQr2nWj0Wg0CY626DUajSbBiTkffUZG\nBrdr1y7a1dBoNJq44pdfftnNzLbhzDEn9O3atcOSJUuiXQ2NRqOJK4jIcXS4dt1oNBpNgqOFXqPR\naBIcLfQajUaT4Gih12g0mgRHC71Go9EkOAGFnoimEtGfRLTKYT0ZU4blE9EKIuppWncFEa03XleE\nsuIajUajcYcbi/5t+JmPEzJbT5bxGgvJKggjnekDkCnM+gB4gIia1qSyGo1GowmegHH0zLyIjImh\nHRgBYJqRuvQnIzd3KwADAcxh5r0AQERzIA3GBzWttB3FxcDzzwNnnQX06VN1/XvvAevWeb+3bQv8\n7W/hqIlGo9HEFqEYMNUGvtOGFRjLnJZXwZi4YCwAHHtsoImC7CkvBx56CGjatKrQHzkCXH45wAwQ\nyTsA/N//AV27Vt2XRqPRRJyCAhGoNv4mZaseMdEZy8yvM3NvZu7dvLm/CYmcadJE3ouKqq4rKhJx\nnzIF8HiArcZkbDNmVC2r0Wg0EaewEBg+HDjzTKCiytS5NSYUQr8VvvNmZhrLnJaHhZQUoGFDZ6EH\ngLQ0eW/dGujfH8h1MyeRRqOpPmVlwMUXA4sWud/myBHgP/8BRowAXnwxfHWrLszi9505MzT7Ky0F\nRo4E1q4FJk0Ckp2mzq0+oRD6WQAuN6Jv+gIoYubtAL4CMJSImhqdsEONZWEjLU0aRitWoQeAUaOA\n5cuB/Pxw1kijqQUwi9VUXFx1XW4u8OGHwD/+EXg/e/YAt9wilthf/gLMnQvcdBPwQVi69arP+vXA\n1KnA3XeLi6AmMANXXw0sWAC8+SYw2O10xcHhJrzyA8jkvccRUQER/Y2IriOi64wisyETTeQD+BeA\nG6T+vBfAI5D5PBcDeFh1zIaL9HR3Fj0gQg9o901QeDxioWmqUloK7NzpfdlZHPFAURGwbRuwZQvw\n++/u/u9vvwUuushezCdOBJKSgO+/B/wlK2QGrrwSePll4IwzgK++AnbtAk49VZYH80Rgt28nKir8\nr7dj9mx5X79e6hkMFRXA3r1yjRQUABMmAO+/Dzz2GHDZZcHtKxiYOaZevXr14urSrx/zkCFVl+fm\nMgPMy5b5Lu/Th7l372ofrvZx3XXMxx3HXFYW7ZrEFh6PXEgiGd7XgAHM77zDfOBAtGvojjffZE5O\n9j2H449n3rvX/3ZXXSVl69Rh3rjRu/zHH2X5448zN27MPGaM8z7ef1/KPvec7/I9e+Saa9qUec0a\n9+dy6BDz9OnMw4YxN2jAfMcdzEeOeNd7PMyTJzOnpjJ37848cSLzrl3u9j1kiNSpVSvmM88MXN7j\nYf7lF+abbmLOyKh6nYwdK2VqCIAl7KCrURd266smQj9sGPNJJ1Vd/uabcqabNvkuf/pp++UaG9as\nYU5Kkh/sP/8J3X5Xr2a+4grmkhL32xQWMk+Zwnz22cxr14auLuXlzOPHM3/xRXDbzZkjv8sNNzC/\n/LK8HnyQuVMnWd64sYidHVOmMN9+O3NFhfP+Dx9m/ugj5osvZn7kEeY//giufm746isR+dNPZ37t\nNeZ//Yv5+edFvE8/3VckzRw4wNyoEfPw4SKaV1zhXTd6NHNaGvP+/cy33CL72rq16j527mRu1oz5\n5JPlP7CyYQNz8+bMxx7L/MYb8v/b4fEw/+9/YpCkpclvf8wxzOedJ5/79JGGaN8+5pEjZdmQISIa\nqqEaNYp59mz7ejDLudSpw3znncwPPyzb+WuA5s9nPuEEKVe3LvNFFzG/8ALzSy8xv/4684wZITOc\nao3Qjx7N3Llz1eXPPy9najVMNmyQ5c8+W+1DRpaCAuYlS4LfrqREHmtKS6t/7Isukhv62GOZ+/ev\n/n6sDBkif8Irr1RdV1oqlt7bbzO/9x7zBx8wX3stc8OGsk1yMvP//Z9/kbRSUsL86adys1t57jnZ\nb716zIsWud/nWWcxt2ghVqQZj0f2M2KE7Pfll33Xv/ee16q7++6q+920ifnmm5mPOkrKKGuQiHno\nUBGLN9+U19tvO1vev/5qL7CKZcukMerenbmoyHfdu+/KMa+4wt7qnDZN1i9aJA1WUhJzXh7zli3y\n/9x+u5TLz5d633df1X385S8igqtXO9fx55/FigakQbn4YrHCX3qJ+dVXpSHt1k3W168vTw9z53qv\njdxcEf+0NOa2bZlTUuTGV+e0YoU08uo3btOG+R//qNqofPKJrF+wQBqounWZb7yxan3Ly6WxT0pi\nzsqS/37PHufzCwG1RujHjpX7zcoDD8iZ2jXSJ54oLp+YZc8esbAGDJAbJSlJWii3VFQwn3++/ADX\nXlu9R8RffpHt779frBGAefHi4PdjZe5cr7B26VJVsJ96yiuE6lW/PvPVV8vx33lHlk2Z4v84Ho+4\nEcaOFUEDpIE4eNBbZv162ffQoSIo6en+hUexZo3s78EHncuUlzOfe64I35dfyrLvvhORGDBA/hdA\nLDzFzJkiSnXrigXz1Veyn40bmf/5T2lwrb/NqadW/Q3z8mQfbdsyb99etW5btoiotWkjn+146CHZ\n/8MPV103aBBzhw7yG+/aJcbAhRcyT5gg16r5cfm880RIzQ3izJmy70cecf79FB4P808/yZNT06ZV\nz79vX7lXnCz+jRulTNu2zD/8YF/myBGxss8+W+pvdTepa0gZTVdcIYaH2XDYvl1+F4D5ssvkKSAC\n1Bqhv+su0Qwr48fLf2PHY4/Jr+B0jUeVw4flBgREfCZMELF/4AH3+7j7btn+lFPk/emn/Ze/8Uax\n7Fau9C4bPlxurMJCsfgC+Vvd4PHIo/Qxx3h9a0oEmeVYTZuK8G7YIC6aVat8b2KPR3ykDRsyb95s\nf5xdu8SnB4iv9oor5Dcgksf0igp5DRjA3KSJPDVt2sTcsqWIqT9LmJn5+uvlotu503+5/fvFqmjc\nWKzCjAyx9Hbvlkf3YcOkIfjiC/EnA+JScPIrVlSIC+f33+X14ouyzUsvecuUl4sV07Sp/Ea9evmK\nzsqV8gjcuDHz8uXOdfd45HcDxMJXbN4sv+NDD3mXKauqYUNxj5iZN0/Wvfmm18XSqBFzjx7BP22W\nlYkRtHOn/EeBfn/zuTi5ZazcdZec36pV3m0zM+W6USgj6PnnpVG98UY5p/r1madODYnv3S21RuiV\naB8+7Lv8yivl/7Fj7VrZZtKkah82fHz9tVRu2jTvBTNkCHO7du7cFVOnyvbXXy/lR49mvz72fftE\ntJTlPG0a87ffyvennvKWu/lm8VNu22a/H49HfJgjR3pf11/P/Oef3jIff+y96Y8ckY6tYcO86++/\nX9b/8ov/c9y8WUTlzDOr3lQ//ih/fN264pYxuyWUm+b228VtBIj/V/Hrr3LDdu0qwmwnDnv2SONx\n9dX+66goKPA23E2b+vYvFBVJA6us0xtvrHoh+8PjkUaxUSNvozdxolecP/tMLNRzzhGRnDZN/uOj\nj5b/OBBHjoivvk4d8TszixVu7eQqKvK6mqzuL49H/NUpKd5r7LLLgntCjSS7d0vjf8EF8n35cqn3\n1Km+5U45RdxJyg9/2WUi+hGm1gi9MmqsjfsFF4j7zokOHeRpM+YYP14uIHNHpfLrLljgf9s5c+Sm\nPOMMr7V06JC4LFJTRQStvPqq7HvWLLFwAblpW7b0rcP69WLp3H+//bGVH7NTJ4naOP54uQFat2Ze\nuFCEpmtXcdeojiglGmvWSIOgXABumDJFtn3gAXnsnjGD+dFHRVDat7dvLDwe5nHjuLITbsiQqg3F\n3LnSUADSuD79tG9j9cQTsm7FCnf1ZGZeulQ6He3+vy1bpLH797/d78/M5s3yuw0dKj7xBg3EBaHO\n6+WXuTKSRkUFOTXWduzbx5ydLS6lVavk/x04sGq5d9+Vxs/Omv3iC/mt/blYYgnltvr5Z+//bf3N\n5s6Vp5InnvC9PiJMrRF61W9kDcQYNEj0zYlRo+SajTk6dxa3iZmSErEyzNENinXr5LEmJ0d+iC5d\nqnY6/vmniF+nTlUfl/v1kxvZ4xEBvuce2c9rr1U91rnnSiSEtQOyvFyEJCvLN5pg6VI5n6Qk6bwE\nRJDN9apXTyz/227zduq5QblerD7b887zHxpYXi4dpU2a+IYFmikrkyeg007jyg5gJVRt2jAPHuyu\njpFCWTtt2sh5WX2Sd90l6++5p3rRHps3S8OvfORvvRWSascsxcXiZhs6VPpAevaMdo0cqTVC/9ln\n3sbXTK9eVfXSjDImi4urfejq89tvIoyffea7fP16duxovPZasdbMFVahRYAI9gsvyKOnHbNmSbl/\n/cu3HnY+fKd9qI7UJ5/0Xa6eOKZPr7pNcbH49pX/2WrxXXWVPM7Xqyf+tmAoLZVHa/Vas8adf7Si\nwj4Cx46VK5nvvdcbNgkwf/55cPUMNxUVIkhODbTH496f7cSSJXL9NWwYsY7GqKLcfIB91FCMUGuE\nftEiOaM5c3yXd+zIfMklztupBuK776p96Oqxc6dY14B01JmFafJkWW7nv/z+e/bxFc6cKa6U8893\nF2Pt8Uj0QWam1yK/5x6xot0+yns84nsnEn87s4hthw7yGOvUh+DxMP/3v/adjMuWcaUrJZYHN3g8\n8oQyfXpEO9tcs21b+DsCFy+WSKDawMGD3r4VO5dnjFBrhF71leTm+i7PyJAOfie2bOEqAQthp6RE\nok7q15fKAczffONdP2yYRNrY4fGIa+S007zW1ckn+4YLBmL+fDnmCy+ICyMz0/9jj9M5nHyy+Px/\n+snr47c+nQTDNdeIf12jiSX+8x9x37iN2IkCtUboN2/mKsETHo8YiHbjUcxlmjUTj0hA3FpJ/sqV\nl4v1TSQdlyUl0umpwtFKSsR9MX688z5UiFHz5hIXvGOHu3qZGTJEtlcRMB9+GPw+du4UK755c4mc\n6dcvNq1cjSbB8Sf0MZGPPlSopGXmxGaHD0teJnNCMytEQI8ewLJlAQ7w3XfAscdKprlA3HorcPrp\nwIEDVdfdfjvwySeS8GnECKBBA2DsWFm2aZPs/8gRmS7Licsvl4ofOQJ88QVw9NGB62TlscckcdQV\nV0hGuPPOC34fLVoAX34pyZq2bwcef1zqpdFoYoaEEvomTURjzEKvPqen+982JwdYuVJmqnLkiSck\n49yoUb7zElopKgJeew1YuBAYM8Z3IoFJk+Q1fjxw883e5TfeKJV/8UXJjtegAXDaac7HyMwEpk0D\n5swBunXzf3JO9OkjDc3+/ZIzPDW1evvp3BmYNw949VVg4MDq7UOj0YSNhBL6pCSgcWNfoVfZYv1Z\n9IAI/eHDfvR7/XoR4KuvlllOzj5b8mfbMWOG7Oyqq4BPP5VUpIBMVHDrrcAFFwDPPuu7TWYmcOGF\nwBtvALNmAUOGAPXq+a/0mDH2E+QGw+OPi1DfcEPN9pOTA/z97zXbh0ajCQsJJfSACLqdRe9G6AGZ\njMSWF18E6tQRd8cnnwB//CGWfWlp1bLvvgtkZclEAjfeKKJ+223AX/8qwvzee/azyIwfL5M3FBT4\nd9uEkuxsmdnmhBMiczyNRhNxElLozXM+uBX6Ll2AunWBZQv2Addf77uT4mLgrbeA0aOBli1lVvGp\nU3H7N+eiQ0YxOnQAOnQQrfz9h61elw2R+OGHDQNeeEFmzpk1S9wydvTt67XQhw+v9m+g0Wg0ZlKi\nXYFQY51lyq3Q16kDHH88sOybQmDdq0Benswek5oKvPOO+LFNPvUZqZfieQBD9s9Bq74nYF+9lvj8\nc2DZqz+hLSBCD4ib58MPgUcflQ7XFi38V2TKFOmMPfbYYE9do9FobEk4oU9Lk+APhdvOWEAibz7/\noBk4pQ5o0SLg0ktFpKdMEWv7pJMAiGv+xhuBE3t4MLvoRtT5nZD/8Qp8/nk9FM1bIhZ/hw7eHTdp\nAjz9tLsT6NOn5n53jUajMeHKdUNEw4hoLRHlE9EEm/VtiWgeEa0gooVElGla9xQRrTJeo0NZeTus\nPnq3nbGA+Ol3HW6CHd2Hiqvl448limT9epmk2ODWW0Xsp76dhDqvvQisW4f0t14AABRtOxDeuR81\nGo0mSNxMDp4M4CUAwwFkA7iEiLItxZ4FMI2ZuwN4GMATxrZnA+gJIAfAyQDuIKImoat+Vex89ERA\no0aBt1UdssvSBkjH6F13yaTGLVtKRAwk8ObddyWQJicHwNChwJgxSJv0MACgMLmZzGCv0Wg0MYIb\ni74PgHxm3sjMpQCmAxhhKZMNYL7xeYFpfTaARcxczswlAFYAGFbzajujLHpm+V5UJJ6TJBdn2uO4\nwwCA5UknyoInnxTf+iuvAHXrorhYIgizs4H77jNt+PzzqNOkPurjIIranwgcdVRoT0qj0WhqgBuh\nbwNgi+l7gbHMzHIAI43PFwBoTETNjOXDiKgBEWUAOB3AMdYDENFYIlpCREt27doV7Dn4kJ4ug54O\nHZLvRUXu/PMAkLZ3E9pjI5aVdFIVA+69Fzj/fABizRcUAC+9ZAlxb94ceOEFpKEIRe1zalR/jUaj\nCTWhCq+8A8AAIloKYACArQAqmPlrALMB/ADgAwA/AqiwbszMrzNzb2bu3bx58xpVxJoGobDQnX8e\nAJCfjxwsw7Lt9ukE1q4V7e/b12bl5ZcjvcNRKErX0TIajSa2cCP0W+FrhWcayyph5m3MPJKZTwRw\nr7Gs0Hh/jJlzmPkMAATAT+6AmqNEXfnpi4qCEPoNG9ADy7Huj1SUlFRdvX49cMwxzpkC0prXQ1GR\nzvOi0WhiCzdCvxhAFhG1J6K6AC4GMMtcgIgyiEjt6x4AU43lyYYLB0TUHUB3AF+HqvJ2WC36oIQ+\nPx/dG2wAM2HNmqqr16+XAa/+jm3uCNZoNJpYIKDQM3M5gHEAvgKwBsBHzLyaiB4mIpXucCCAtUS0\nDsDRAB4zltcB8C0R5QF4HcAYY39ho6ZCn91enPt5eb6rmCUPTiChN4d2ajQaTSzgasAUM8+G+NrN\ny/5p+pwLINdmu8OQyJuIoTpezULvtjMW+fno2LMP6qyrKvR79oi13rmz8+Za6DUaTSySkLluAG+I\npa1Fv3w5cP/93hhMQJLWb96MlM4dcNxxVYV+/Xp592fRW9MvaDQaTSyQsEJfWAiUlEgqeB+hLy0F\nLrlE4uNXr/Yu//13KdypE7KzUcVH70bo09IkrNMuoaVGo9FEi4QT+kaNZHBUUZFDQrNnnvGq+Ny5\n3uX5+fLeqRO6dgU2bvTG4gMi9ElJQPv2zse2m+FKo9Fook3CCT2R11deRejz88WSv+gicbbPmePd\ncMMGeTcseo/HdxKS9etF5OvWdT62FnqNRhOLJJzQA1WFPj0d4o+/4QZR6okTZQanb77x+lny84GG\nDYGjj0a20X1s9tMHiripPA600Gs0mtgiYYW+sNCSufKDD8SCf/xxmQDkjDPEif/TT1IoPx/o2BEg\nQlaWTAClhJ45cAx95XGghV6j0cQWCSv0Pq6bJgzccYfkk7/uOlk4cKA43ZWfPj8f6CQ5burVk49K\n6HfuBA4ccC/0etCURqOJJWqH0FOxzEZy8cXeuVrT02WCj7lzJdpm48ZKoQckQ6USejcRN+q4gLbo\nNRpNbJGQQq/i2St99OW75YM1YdqQIcDPP0uYZWlpFaFfv14WK6H3N1hKHRfQQq/RaGKLhBR6s48+\nORloUGKkPs7I8C14xhlizb/xhny3CH1FhYj8unUyp2ygaVybGFOq1EahP3IEqGGGaY1GEyYSVuiL\ni70pimm3g9D37SuRNtOmyXeT0HftKu9r1ojYd+gg83z7IzlZ4vhro9BPniyTq5sHG2s0mtggYYXe\n4wG2bTP85rsN141V6OvWBQYMEGWuVw9o451P5bjjJCY/L89dxI352LWxM7agAPjzT+Dw4WjXRKPR\nWElYoQeAP/6wCL3dpCZDhsh7hw4+8w02aCADpFatkoCcQP55RW3Nd6Py99fGRk6jiXUSUuhVp+jv\nvxufd+8Wi71hw6qFzzhD3k1uG0V2NrBggaRCCMair41Cf/CgvGuh12hij4QUemXR791rsugzMsQX\nY6VbN3n1719lVXa292FAC71/tEWv0cQurvLRxxvmJGY+Qm8HEbBypW0jkG3KpB+M0KtwzNqEtug1\nmtgloS36ys/+hB6wt/ThFfrUVCAz0/2xtUWv0WhiiYQUevOMUpU+en9C70CXLvLeqZNPP23AY9dG\noVcWfW08d40m1nElX0Q0jIjWElE+EU2wWd+WiOYR0QoiWkhEmaZ1TxPRaiJaQ0STiRzM5xAStEXv\nQOPGEoyjYurdHru0tPaFGWqLXqOJXQL66IkoGcBLAM4AUABgMRHNYmbzZHvPApjGzO8Q0SAATwC4\njIj+D0B/AN2Nct8BGABgYehOoSr168vgpvJyIK1RBbBvX7WEHgA+/TSIOWfhm+8mNbVah4xLtI9e\no4ld3Fj0fQDkM/NGZi4FMB3ACEuZbADzjc8LTOsZQCqAugDqAagDYGdNKx0INfkIAKSlHJDhmtUU\n+uOPd++fB2pvBkst9BpN7L0jCcMAACAASURBVOJG6NsA2GL6XmAsM7McwEjj8wUAGhNRM2b+ESL8\n243XV8xsmY0VIKKxRLSEiJbsClHClEqhZ8NpXE2hD5bamthMu240mtglVJ2xdwAYQERLIa6ZrQAq\niKgTgK4AMiGNwyAiOtW6MTO/zsy9mbl3c7vRq9VACW56xR75ECGhr42pisvK5AVooddoYhE3cfRb\nARxj+p5pLKuEmbfBsOiJqBGAUcxcSETXAviJmQ8Y674E0A/AtyGou18qLfoyhzw3YT5ubRJ65bYB\ntNBrNLGIG4t+MYAsImpPRHUBXAxglrkAEWUQkdrXPQCmGp//gFj6KURUB2LtV3HdhINKoT9sdAlo\noQ8bWug1mtgmoNAzczmAcQC+goj0R8y8mogeJqLzjGIDAawlonUAjgbwmLE8F8AGACshfvzlzPxZ\naE/BnkqhP7hdPjRrFonDVrqMapPgKf98gwa167w1mnjBVQoEZp4NYLZl2T9Nn3Mhom7drgLA32tY\nx2px1FES3phauEOSmdWvH5HjNmokUT+10aJv3RrYssV/WY1GE3kScmQsANxyC5CbC9Ce6g2Wqi5J\nSTLTVG0SemXRt2kjM03VtsFiGk2sk7BC37YtcPbZqPao2JpQ2/LdmC16QLtvNJpYI2GFvpJduyIu\n9OnptUvszBY9ULvOXaOJBxJf6LVFH3a0Ra/RxDZa6MNAIKH/+Wfgww8jV59woyz6cAv9/Pky45dG\nowmOhJx4pJIjR4D9+6Mi9Hl59uuYgauvlvZn9OiIVitsKIs+3K6b++6T9x9+CM/+NZpEJbGFfk9k\n0x8o/Fn08+YBq1cnVmbLSFn0hYVARUV49q3RJDKJLfS7I5v+QKE6Y5mrTl41caK8Hz4seevr1o1o\n1cLCwYNyni1byvdwCX1RkfxmGo0mOBLbRx8loU9LE8vTnBoAkLlkv/gCaNVKvhcXR7RaYePgQRkV\nW7++NFzhFPq9ewGPJzz712gSFS30YcAp383kySKE48fL90QR+pISGXxMFL7Q0rIyOY7Hkzi/m0YT\nKbTQhwE7oS8sBN56C7j4YqBz56rr4xll0QPhmzPXLO6q60Wj0bijdgh9hBKaKewmH5k6VSzSW26R\nFAnW9fGMsuiB8Fn05t9KC71GExyJL/Tp6UCdOhE9rHU6wfJycducdhrQs6d3fShdECUlwMcfh25/\nwWC16MMt9Hv3hn7/Gk0ik/hCH2G3DVDVdTNrFvD772LNA+Gx6D/6CBg1Cti4MXT7dEskLHrzPrVF\nr9EEhxb6MGAV+kmTgHbtgBEjfNeH0qJXQrhjR+j26RazRZ+Wpi16jSbW0EIfBsw++l9/BRYtAm66\nCUhOluXhsOjVoKUQza0e9LG1j16jiV200IeBBg1E1AsLxZpv2FDSHihSUyXMMpQW/YED8h4Nobf6\n6A8fDn1OeiX0SUla6DWaYHEl9EQ0jIjWElE+EU2wWd+WiOYR0QoiWkhEmcby04lomel1mIjOD/VJ\nOBIloScSF8a6dcD06cBVV3mtfEWoM1xGU+itFj0Q+ogitb9jjtGuG40mWAIKPRElA3gJwHAA2QAu\nIaJsS7FnAUxj5u4AHgbwBAAw8wJmzmHmHACDABwE8HUI6+/MwYPAoUNREXpAhPzjj2XI/s03V13f\npEniWvRA6N03hYVyjKOP1ha9RhMsbiz6PgDymXkjM5cCmA5ghKVMNoD5xucFNusB4EIAXzLzQZt1\noSdKg6UU6ekyivPss4GsrKrrw2XRq9OOFB5PZIS+qEh+s6OO0ha9RhMsboS+DQDzlM8FxjIzywGM\nND5fAKAxEVlHKV0M4AO7AxDRWCJaQkRLdoXKJI2y0KvIGpXuwEqo55WNlkWvfPFW1024hL5ZM23R\nazTBEqrO2DsADCCipQAGANgKoDKhLBG1AnACgK/sNmbm15m5NzP3bt68eWhqpBQvSkLfoQPQqxcw\neLD9+rS0xHDdqGifSFj06eli0Wuh12iCw02a4q0AjjF9zzSWVcLM22BY9ETUCMAoZjbf6n8BMJOZ\ny2pW3SCIskX/2muSiMuapliRKBa9ytAZbou+sFBEvlkz+d3Ky4GUxE6yrdGEDDcW/WIAWUTUnojq\nQlwws8wFiCiDiNS+7gEw1bKPS+DgtgkbURb6lBRJ2+tEJC36oiLgnnvCk8tdCX2kfPQqbdG+faHd\nv0YTDvbskZnRyiJn4toSUOiZuRzAOIjbZQ2Aj5h5NRE9TETnGcUGAlhLROsAHA3gMbU9EbWDPBF8\nE9KaB2L3bgm6tsY1xghK6JlDsz8l9IcOed0pii++AJ58EliyJDTHMqOOpSz6+vUltVA4O2MB7b7R\nxAezZwOPPRaeey8YXD38MvNsALMty/5p+pwLINdh282o2nkbfvbvF/VRw1FjjCZNvJOTKJGsCQcO\neEel7trlu8+CAnkPhxVstejDlZNe+eiVRa8jbzTxgHLPbtoE9OsXvXok7sjYw4f9+06ijNPkJNXB\n4xHLun17+W5134RT6K0WPRB6oT9yRP5ObdFr4g3lnt20Kbr1SGyhj+EZuFW+m1D46ZVVHQ2ht1r0\nQOiFXjWGZh+9tug18YC6dqORVdaMFvooEUqLXvnnnYR+qxEjFY5kY5Gw6O2EXlv0scuhQ8DOndGu\nRWygLfpwE+NCH8oMloGEPlEs+vR0+d2Sk7XQxzIPPQT06RPtWsQG2qIPNzEu9KHMSa+EvlUryYpp\nFvqyMmD7dvkcrz56s0VPpNMgxDpr1wJ//JE4U2XWBPUbbNkS3RBLLfRRIhyum8aNZdiAWeh37PCG\ncIbDdeNk0YfyJlf1Vr+ZHh0b22zbJu/RdlfYsWIF8HVk0ioC8BpyHo80ftFCC32UCGVnrBL6hg2B\n5s19hV65bYDwWfT16vlGsaani5/2yJHQHMNs0QPip9cWfewSy0L/j38A110XueMVFQFNm8rnaLpv\ntNBHicaN5T2UFn2jRs5C3759+Hz0ZmseCH1Oejuh1xZ9bOLxeKezjLZf2o68vMgaCcXFQE6OfI5m\nw5fYQh/DcfTJySLMobToldCbUxUroT/hhPBZ9E5CHypXkRJ69RSkXTexy+7dkocIiJywbd8OnHVW\n4DxPJSXA5s1yPVVU+C8bKoqKgK5dZbS4tujDQYxb9EDoctIHsugbNBCLPlw+euvI3lALfWGhPAEp\n95B23cQuym0DRE7YFi4EvvxS5mb2x9q13v6qSHQUM4sh17Qp0LattujDQxwIfahmmbIKfXGx1z++\ndSvQpo1cbPv3e62tUBEpi165bQCx6EtKQtcHoAkdSuhbtw69sDn936pBWbfO//Z5ed7P4TB6rJSU\niCsrLU3SlmuLPhzEgdCHyqIvKZGww/r1RegBr/umoADIzPR2CIX6Arez6JUoh0vo9ejY2EWF8vbv\nL0Lv8YRmvwsXigGxdWvVdapBWb/e/z7MQh+J7KfKiGvSRJ6otUUfDuJE6ENl0TdqJGKvhF65b6xC\nH+oL3F9nbCiF3pyEVI+OjV2URf9//ycWuOqYrSkrVsgtvXx51XXKUo41oTcHEbRvL9drKFOTB0Ni\nCj2zXGUxLvShmnxECT3gK/Qej1hA4bToS0oi46O3um4ALfSxyLZtMpajSxf5Hip3hWow7NwzwVj0\nxx0nnyMp9E2aiOsGiJ5Vn5hCr5x5MS70oeyMtRP6P/8Un3xmpld8I2HRN2ggUQahcq1o1038sG2b\njNAOtbApobeKeVmZDERq2FDy6zhZzIcPAxs2yJMGEBkfvaqLsuiB6PnpE1Po1YzVMS70oeyMtRN6\nFVoZTteNnUVPFNpYd7vOWEBb9LHI9u3SEdu2rVwHobborUK/ZYs8uZ5+uv16xfr1Uq5/f/keadeN\ntujDQZwIfVqaCGVNI2HMQt+0qUysFSmht7PoAXl8D4UQMzv76BPNoi8rA264AcjPj3ZNqs+2bSL0\n9epJtFe4LXrVkJx5pv16hfLPn3SSTPMZ6c7Ypk3lXVv0oSROhF4NANq/v2b7MQt9UpIIoZPQR8JH\nD4jQmwduVZfDh0UAzRZ9gwYiJIlm0a9ZA7zyCvDAA9GuSfWoqBBBbt1avrdvH3qL/vfffcMsVUMy\nZIi8+xP6pCTx0aenR96iJxKrPqYteiIaRkRriSifiCbYrG9LRPOIaAURLSSiTNO6Y4noayJaQ0R5\nxhyy4SVOhD5Uic3MQg94B01t3SrZLDMy5KeoWze0F3hZmTyN2Fn0zZqFRuitCc0AbwbLRBN6FZr4\n0Ue+A4/ihV27ROxbtZLvoRK2igrpb2rXTp7wNmzwrtu4UfqDsrLEoPEn9B07ioHQtGlkffTq3gxl\nwxcsAYWeiJIBvARgOIBsAJcQUbal2LMApjFzdwAPA3jCtG4agGeYuSuAPgD+DEXF/RJnQl9TP72T\n0BcUyONzUpKIY9OmoRV6uxTFilC5bqx5bhSJODpWiXt5OfDyy9GtS3VQDZXZot+61XmgE7PkrX/9\ndf/73bNHxP7UU+W7Wcw3bZL+gORkoHNn/0KfbahWqO8DJ4qKfEd0d+ggKRhCNbYgGNxY9H0A5DPz\nRmYuBTAdwAhLmWwA843PC9R6o0FIYeY5AMDMB5j5YEhq7o84EfpQTT4SSOgVob7A7VIUK5TQ1/Si\nNk86YiYRLXol9GeeCbz6qmQAjSfMo2IBETZmcbfYsWULsHgx8PHH/ver3DZ2Qr9xozeiJSvLPvyy\nrEyWR1roi4u99zgg9Tx8OHRjC4LBjdC3AbDF9L3AWGZmOYCRxucLADQmomYAOgMoJKKPiWgpET1j\nPCH4QERjiWgJES3ZFSgzkRviROhDYdEz+xf6zEzv8lA/sgay6Csqat6I1TaL/qijgAkTpBH797+j\nXaPgsAp9oJDCZcvk/X//828QqGkJu3aV/91q0auIlqwsuSas10V+vjwlKaGPpI/efN1GM/ImVJ2x\ndwAYQERLAQwAsBVABYAUAKca608C0AHAldaNmfl1Zu7NzL2bq/jAmhAnQh8Ki760VC5iq9Dv3SsW\nk1noQ32B+7PoVWRMTf30dj56tf9Es+hVaOKAAUCPHsDEid4kXPGAEvqWLeU9kLApoS8s9J+nRlnA\nLVuKmCuh379fri+zRQ9Udd+oiBuzRR8JH31RUVWLHoiOn96N0G8FcIzpe6axrBJm3sbMI5n5RAD3\nGssKIdb/MsPtUw7gEwA9Q1Jzf8SJ0IeiM9ac0Eyh2sojR6pa9OHw0Tu5boCai7GTRa9cN/EkhIFQ\ng42IgFtuAVatAubPD7xdrLBtm1x7derI95YtpfPTn0Wvrp3//c95v2ah79zZ2yioBkQ1KJ07y7ud\n0BN5R+uq+yDc105xse91266dvMeqRb8YQBYRtSeiugAuBjDLXICIMohI7eseAFNN26YTkTLTBwHI\nQ7hRzs04EfqauG78CT0QXteNsuidXDdAYIt+927g6aedH939uW5KS711SARUDDoAXHKJ/I+TJkW3\nTsGgnkgUSUn+k3ktWyZ55Js0AX76yXm/O3bINdaokVjtW7fK/64aECX0HTrIMa1PB2vWiMiqRqVp\nU3ErqnsnXFgt+tRU+X1i0qI3LPFxAL4CsAbAR8y8mogeJqLzjGIDAawlonUAjgbwmLFtBcRtM4+I\nVgIgAP8K+VlYiROLPjVVBm+Ey6IH7IU+VL3+/ix6t66b6dOBu++WpFV2FBXJzWs+PyDxRsd6PL5C\nmZoKXHWV5FkPtyCFCnNDpXAKKSwqkgagZ0/g5JMDC71yByn3TH6+twFRLpG6dSUCx86izzbFCYY6\nF5MTVosekAZn8+bwHtcOVz56Zp7NzJ2ZuSMzKxH/JzPPMj7nMnOWUeYaZj5i2nYOM3dn5hOY+Uoj\ncie8xInQE9U8g2UwQp+eLoJS0wFaCjcWfSAhDpR5sLBQrKIky5WaaKNj1cxMZqEcOlSWBZpQI1aw\nE3qnWHrVsOfkAH37yndlOFixE/r16+XaSUvzDgZU683XUkUF8Ntv0pGrCNcocSvWzlgAOOYY+1TL\n4UaPjI0yNc1g6U/ok5O9NwgQ+gvcn0XfuLH4agNZ9IGE3u5mAbxCf8YZ0phlZgLXX++u3rGIikFX\ng40AScBVrx4wb1506mRm717JE+OUnqGiQqJjzPUHvDObWa851RHbo4dY9B4PsGSJ/b7thH7dOmlA\n2rcXg0mhhF7531etkr6qSAt9ebkYQmbXDSDhzgUFke9b0kIfZcJh0SsRbNXKO1gDCH0aBH8WvUps\nFkjolbXnFHXhJPR9+gC33gqMGAEMGyZPEO++G53BKKHAGpoIyEQy/fvHhtD/9hvwww/A11/br//z\nT/nt7Sx6oKpVv2yZGCStWonQA87uG7PQN24sn5VFr/av6NxZ7ieVpvvmm+X6Oessb5lICL05c6WZ\nzEyRp0iEd5pJbKGvVy+69XBBIIt+927/ExnbCX2dOnIxm902QOgvcH/hlUDgfDfM7ix662ApQNrw\n558H3nhDXjffLE8Y5uHx8YSd0APA4MEy2UYohpfUBPX0lucQSuFUf6eQwmXLxG1DJNdJp072Qn/k\niDxNmJ9M1cAoZdGbMVv8r70mbq/nnvPdvjo++oqK4PqDzAnNzKh7UuWhihSJK/T16vk+08Uo/iz6\nsjKxUO6/33l7O6EHpFOqUyffZaHOSV9SIr5zp/Y0UBqEPXuk/snJwbturOTkyLtyCcQb1hh0xeDB\n8r5gQWTrY6W6Qt+hg9yGv/7qXVZWJi4V9Z8B4qf/6aeqLo0/jYQpRx/tXZaVJW6ew4erWvRK6OfN\nA+66S5KdXX21b5nqGDxPPSX7LitzV94pWkwLfSiJg2kEFf4mH8nPl4vx5ZedIy+chP7TT4EXXvBd\nFg6LvkED5/Y0kEWvrLx+/cRitbOwrLNLOZGdLRFM8Sr027eLq8vaaPbqJVZhtN03boXe6qNv0kTc\nJm++6X3Q/u03CY21Cv2OHTLIz4w5hl7RubM3f47Vom/XTq6DRx6RRuNf/6p6fapsksHcB+++K+Xd\npi8wzy5lRgt9KIkjoffnulE3VVER8M479mWc0hAce6w38kURah+9U4piRSAfvfLbDh0q73ZWvVuL\nPjVVOtzs5hSNB+wiVgARrQEDoi/0yk23c6f9U9r27SKeZstbMX68WObTp8t39R/16OEt07evvFvd\nN3ZCr6x2oKpFn5IiyyoqgCef9A5SMpOUJNeUW6HPy5PGCXAv0E4++pYt5fha6ENBHAm9ct3Y9cIr\noe/eHZg82b6j8cAB6bRLrpJBqCoqk16oLXonMjLEv+rUQRpI6Jnlt7Hz0duRkxO/Fr2T0APivtmw\nwTk5WCQwhz6uWVN1/bZtQIsW3lGxZgYPBrp1k8FfzPIf1avnnb8VkGs8NTV4oW/b1v54w4bJJC5O\npKe7N3hyc72f3Qq0k0Vfp46cixb6UBBHQt+kifj91GOtGTWib8IE6Vz673+rlrEmNPMHUWjz3QSy\n6AMlNtu4UcShRw+pm1XoS0pkezcWPSD72bo1+h2X1SGQ0APRterNQm/nvvFXf5XSYdky6Rxdtgw4\n4QSxvhV16oibyknoW7TwLuvYUd7btLG/zV9+GZg9u+rYCzPBpAPJzQWOP14+19SiB8R9o4U+FMSR\n0PtLg6BG9F14odxEdsPhgxF6ILRCH8iiDzQ6VkVNpKbKQBKr0DslNHNC+XzjzX2jZmay+rcV3bqJ\nSyTaQp+cLA17sEIPAGPGyPUwcaI34sZK377AL7/45q/fsUNGQZv7Lho0ELG0+ufNBIrDcCv069YB\nK1cC11wjT841tegBLfShI46E3imDpRrRl50t1s6NN0oM8+rVvuWCFfpQ5rtxY9EDzkIfKJe4U+SC\nE8rnG2/uGxVC688iHjRIEpxFK4mb+q+7drV33Wzf7txQASKSf/878Mkn4uO3E/pTTpFOWnOCs507\nq0YiARKJdsstwZ+Hwq3Qz5gh76NGBSfQxcXyxFK/ftV1WuhDRRwJvZNFv2mTWDYqR8fYsXJKkyf7\nlquO0Adj0fsTFjc+esC+8668HPjjD9/Mg+YRjUDwQp+RITdRvAm9U2iimcGDxbp1inoJNwcPitBn\nZ1etQ3m5CLK/+gPiM1fuGnNHrGLgQHG3mJ9czIOlzIwdK0+61cWtjz43V5401Ohrt+kLVBCB3ZNF\nZqakIanpzHLBoIU+yjilKrbm0M7IkMffd9/19eeHU+j/+EPqN3eu/fqSkuq7bgoKRCDMFn1hoW+j\noGKozblMAhGPHbJuhR4Avvkm/PWxw2zRFxT4itQff0gDHUjo27QBLrpIxLx796rr09PFT+9G6GuK\nm/tg40aJ/1cNSrAWvZ3bRu0HiGzOGy30UUZdDNbWXQm9yqENyOP7oUO+oz8PHPDvPrESjI/+o4/E\n8vjyS/v1yspzwp/rxppL3G7SiNmzpRGzs/6cyMkRl5dd53as4hSDbqZtW8nOGI3Mh4BX6JXhYXbf\nfPGFvJ9+euD9TJ4MfPWVswgOHiyuGzU+JJxCf/iw/+vE7LYBvBa9mzQb/sKC1fSekXTfaKGPMv4s\n+jZtfC8W8/BuRXV99G58vSqszCkHSSCLXiU2s3PdqMFS1tmB1LmVlwMzZwLnnBPcX5mTI/5ua19G\nLOM0KtYMkVjMqmykUf+1Enqz+0ZFpaiJP/yRkSGjVZ0YPNibsfPAATluuIQe8G/0zJghTxgqFj8z\nU+qmnjT9Yc1FbyYag6a00EeZZs3kUdaao8WaQxuwt3qrI/SlpYEnnt6yRSyrxo0lEqLUJrl0IIte\n5TFxsuiTkyXaBhDBT0ryntu338p2wfph4zEVwvbtkuCrbl3/5Vq39ma5jDTKom/fXiJglNDv2CH/\nVU385Wb69/dm7FShlXaDsGpKoHw3hYVy/Y8Y4V0WjEDb5aJXKBeXFvqaEkdC37ixzG4/c6Z3mcfj\njbgxk5Ym8cQ1FXogsPvm44/l/e67pVPYGrLo8Uhj4c+iB5xHx27cKKN3Vedc3boiIurccnNl38OH\n+9+/lfbt5feIJ6EPFJqoaNUqeha9atSTk8WdqIR+5kx5OgyV0NevL+mZzUIfDYteuaZ6miY+DUbo\n/Vn0qanSsGuhrylxJPSA3CSrV3svri1bxIKyCj3gO7FCRYWIbbBx9EBgoc/NlQ6zyy+X79Y5PdUT\nQaD+AX8WvV1CqvXrpRH5+GPJkRKoIbGSlCQ+/XgTen/+eUW0XTfqv+7a1Sv0ubki/HbXanUZNEgM\ni5Ur5Xs0hF6dnzmPfagserUvLfQ1Jc6EfuRIeVedP9aIGzPmeHM1WrE6Fr2/0LLt24Hvv5cGKDNT\nBMbqp1fZCO1yiZhxymBpjqFXqHP7/nux5lQnWLDk5IhQxEtuercWfevWIiBOMzGFE7PQZ2dLp/Dv\nv0sU0KhRoU0UqyKMVG6ccAh9IIMnL0+eLswpFjIypM8pkEAz+7fogRgVeiIaRkRriSifiCbYrG9L\nRPOIaAURLSSiTNO6CiJaZrxmWbcNOR6POJTjSOhbt5bHVavQm60JRVaWCPGBA86ZK/3hxnWjHsfV\nDaxSyJrJzZWfeNgw/8ezc92UlEiHlp1FX1ICvPii+GnPPtvdOVnJyZFoIadJqWMJNTOTW6EHouOn\nN3e8KwPkqaek/qFy2yhOOklcmosWiatIhemGkkAGT16ePKmYc0glJXlniPLH4cPSaRtXFj0RJQN4\nCcBwANkALiEiq635LIBpzNwdwMMAnjCtO8TMOcbrPIQbNX46joQekJtl2TJJTZyXJx1Qdhe4eXLk\nUAj90qUSLfHKK95InNxcaWTUDd23r3QWqxwyHo80SsOGyQ3pD2XRm61r66TOChW1kZvrbt9OqA7Z\nbt3ECm3YUHytsRiJ4zQzkx2qTKTdN8xVLXpAUg937Bhc+KsbVMZOQPqk3CTsCxY3rhu7J2o3Au1m\noF9mpiT8U1lBw40bi74PgHxm3mhM7D0dwAhLmWwA843PC2zWR444mkbQjHJTzJghF5mdNQ94xXD9\n+uoJvTnaoLQUuPJKEfEbbpABWZs2yeO42UpTKWSVn/5//5N4YjeWXEaGCJk5fNQaQ69QjZjHUzMr\nsWdPSVF7001yXtdfL+LYpw/w3nvV3284cBNDr1BlIi30paXynyih79RJxLi0VP6ncMzvo9w34XDb\nAOKCadjQXuj375dBYNUVeqfZpaz7ASI3aMqN0LcBYJ4OoMBYZmY5AMPTjAsANCYiZY+mEtESIvqJ\niM63OwARjTXKLNlV09SDcSr0xx4rQvSf/zhbE4B31qh162om9Pv2yaP3ihViQT/6qPhEe/SQm9rs\nH+/VS6wqJfS5uXKjnHNO4OPZjY61xtArjj1W9ut2304kJUm00DPPyOvZZ+XJpXdv4LLLgOuu802c\n5URFRWjcP3v2OM+05WZUrMKtRR9MvXfvDjw5vXXOgzp1vAZHdftRAhFuoQecBw+q3PNOQr91q/9x\nKG4teiC2hN4NdwAYQERLAQwAsBWAmum0LTP3BvBXABOJqKN1Y2Z+nZl7M3Pv5s2b16wmcSr0gNw0\nv/wiFoGT0DdsKDd8dS365GSxNL7/Xmbhufhi4IILgHvvBebMkQ6o7GzfIeoNGsh3NdXbjBmSQ95N\nDhq70bGbNkmdrROjpKRI+tqzznKfg94trVpJyN7dd8tcouPHB97mxRflqePuu8XnWl3++lcRLjtx\nCEbo09Plsg7ko3/pJXki3L8/8D7PPluefPxhN7lNr15idPTuHfgY1eH446Xht06HGUqcEvz5C4ZQ\nk3vv3eu832As+kj56VMCF8FWAMeYvmcayyph5m0wLHoiagRgFDMXGuu2Gu8biWghgBMBhG8KZyX0\ndmnjYpxRo0RUAP/haioMsTpCD8gFPmeOCK05SdqgQfKkUFZW9XG8b19xe/z8s0RbPPigu2PZJTZT\nETd2j/xffhm+NjolRVw6ZWUysfjo0ZJIy4nPP5e6PP008OOP8sTjRpCt/PKLnP/8+V5LVeFvZiYr\nbkfHfvGFPLHs3u2/1fUKiQAAH+5JREFUn6O8XJ50AoWwKqE3l3vxRbnVwjUtM5E8QQZ7bQeDU76b\nvDwZ12F1LQK+Au3USezGoo90GgQ3Fv1iAFlE1J6I6gK4GIBP9AwRZRCR2tc9AKYay5sSUT1VBkB/\nAOHNvxfHFn3HjsCJJ8rncAq9spanTJGBG2bS0qpa2oAI/f794uJJSQHOc9mt7mTRO+USb9HCvyUU\nCh55RH7ra65x7gw7fBj47jtJrfv++yLWJ54ok1IHw65d3kZu4sSq67dtk//AbmYmOwINmjpyREaq\nAoFdMhs2SKMXrOsGkP/IPBlIOGjZMnpC37mz78QoCjeWuL9c9IqGDeX4MSP0zFwOYByArwCsAfAR\nM68mooeJSN3uAwGsJaJ1AI4G8JixvCuAJUS0HNJJ+yQza6H3w003SXIofzdR584iIOoiCfZmOP10\n6YQdPdr9NqpD9vPPxfI/6ih321l99L//LjeSXT7ySNGggUSMbNggec3t+PFHuZQGDxbXy+LF4vt+\n7rngjqXcAP36iaVtHtW8c6e4wYL5LQJZ9D/95B3MFkjAzXMS+0M1hsEkz4sHnFIVr1njbGi5EXp/\ns0uZcROqGSpc+eiZeTYzd2bmjsz8mLHsn8w8y/icy8xZRplrmPmIsfwHZj6BmXsY72+G71QM4lzo\nr7pKHvH9PRKr6BQ1+jNYoX/hBeCtt4J77M7K8oakBRMRoxKbKaF/8UU57rXXut9HOBgwQKJxJk60\nT9o2b570Z6gwv+xs8UvbTWDuDyWmkyeLhThlinfdTTfJU5mdpe9EoHw35hS/gfKtq7oFKuc0AX28\nY2fRHzokrkUnoW/ZUq4LNxZ9oPDgSMbSJ97I2DgXejcooV+6VMQjUDKsUKAGTiUlAefbxk45b6di\n6Q8cAP71L++I22jz5JNiVf3tb2Ktm5k3TwbumB+/lcssmFme8vLkhu/VSzq+33pLhGDmTImweuAB\n51BaO1q3FheaU0frvHnep8FgLHp/55TIQr9/v29H+9q18ls4CX1ycuDJvYuL5akxkDtOC31NqAVC\n37GjCOjmzWLNh6tDzMqECWKZBhsYpUbHTpsmouIm4iUSNGkioZd5eeKSUhQXi6vG2nHaubOsc5Om\nVqFCZdUE2QcOiPvnhhvE53/nncHV2d/o2P37pbNcNcRuhb6iwv/AHbvO2ETAbnSsv4gbRSCBDpT+\nwLyfnTvtM8OGGi30cYiaTBsIb2eVldNOk7lrgyUjQ/oUJk0CTj7Z6++PBUaOlDA+s/vkm29E/KxC\nb5cmOhDmwW+9esm8qI88Ig3f1KnuO2EV/gZNLVok1ukFF8h3f0Kv5iRW7gV/ZRPVordLVZyXJ1a7\n+q/tsBN6FRgBBE5oZt4PEJkBcFro4xQ1YCWSQl9dMjLED75uXc0mdA4HKSnAuHHAwoXeVMzz5snl\n06+fb9lghX7vXknOZrYOb71V3idMqF6HtD+Lft48yRE0YIBY3/7Ee/NmuVVUo+uvbKJ2xtqlQcjL\nk9h9f+7QzEzJMKvcXU88Ift64QVvQjM3Qq8Spv34Y/XqHwxa6OMUJTrxIPTNmokF2bp16BNghYJr\nrhFhnDRJvs+bJ5a39RJq104aBrdCr9JOm4X+gguk0XM7DsGKv9Gx8+bJxB3164vQ+OtkVXVTjZm/\nsolq0TsJfaCUy5mZ8psUFwOrVkk/S9OmwG23yfW9bZs7182AAdLY33ab++k9q4sW+jglnoRexdKP\nGxe8qyISNG0KXHEF8O9/y427alVVtw0gIm+eHCUQdkJPJO6r6ibqatJEGiWr0P/5p6SzUPVOS/Nv\npZvDPoHArpt69cKTXCyaKKFXo1yPHJFkgW6EHpB8OH/7m/zWq1ZJ38unn0oefTcWfZ064r7btUvE\nPpxooY9T4knou3eXSJBoh1T64+ab5UYfM0a+2wk9IC4z85y9/rDLaV5TiOwHTS1YIO/BCH2rVtI/\nAQQW+kTriAVEsBs1Au64A/jhB2nAKyrcC/2dd0rn95Qpcn3fdpu4ADMzgeOOc1eHE0+U0fBvvy2T\npoeLxBX6SMQcRpF4Evq//EV8ynYjbmOFLl1k2sLly6WTzjyFnJmsLLH63IRYqo7YpBDfZXaDpubN\nE2u/Vy/57kbos7O9HZKBhD7R3DaA/EaLFnn7Nf7xD1nuVui/+kpGiJsHHp5yivR/PPqo+3rcf79c\nJ2PHustPVB0SU+hTUyMXcxgl2reXR+l4EHog9GIXDlRH8cCBzm6KrCzpnHQTKeHG31sdrIOmmEXo\nBw70Dtt3GvWpyqu6KReDPx99oEng45kTT5T0FuecA3z2mchGIGtc9ZOkpck8DlapSU4OTn5SU2Wk\n9pYt0kkfDtwkNYsv4mwawepSt65cFKecEu2aJA5Dh0pum4suci5jjrxpY03WbaK4WG7cYAZDuaV1\na4n7ZxZBycuT0Zx33OEt48+iN89J3KCBCFNttOgV6ekyR/GLL0qUVKB8iHXriqtv8ODqJbmzo18/\nGV+yf7+kCQ+1YaSFPo4J5vFQExgi4NVX/ZcxT/ziL/Olv5zmNaV1axHf/fvFXZObK3VX8fOAf6E3\nDwoiCuzmSXShB+R3CJSu2YyK0Aolzz4bviffOHigDpJaJPSayHPMMeLTDdQh62aEZXWxDpqaMUOe\n7MyTdKSlSd6WsrLAdXMj9InYGRtrhNO9qYVeowmCpCRJQREoxNJfTvOaYh40tXathPNZxyco37ud\ngK9ZI2ksVOd4erq26BMd7brRaIJEJTfzx5o10qlnl9O8ppgHTalRlSNH+pYxD++3RjtZO4kDDa5K\n5M7Y2oK26DWaIMnKklz21oyXZsIVcQP4Cv2MGZLGwJoN1MmiN0fcmMtqiz6x0UKv0QRJ584yuGrL\nFvv1Bw/KLFrhEvrGjUV4v/sO+PVX+7QSTkK/Y4dY71roaxeJ6bpxO/2RRlMNzCGW7drJ5+nTgblz\n5bPK7x4uoQe8IZaAzDVsxUno7TqJ/fnoPR5puHRnbHzjyqInomFEtJaI8omoSkg/EbUlonlEtIKI\nFhJRpmV9EyIqIKIXQ1VxRw4d0ha9JqxYs1j+9JNMNzhzJvDf/4rfvEsXSTAWLlq3FhHu1cvb2Jix\nS8ELyJMGIBkaFcqi93iq7kcNNNcWfXwT0KInomQALwE4A0ABgMVENMsy9+uzAKYx8ztENAjAEwAu\nM61/BMCi0FXbD9p1owkzrVuLhbt+vbhwrr5afOSrVoV/YnNzHQDnbKD+XDcAcPTRvmWZJae6tf6J\nmrmytuHGou8DIJ+ZNzJzKYDpAEZYymQDmG98XmBeT0S9IBOGf13z6rpAC70mzBB5I28eeUQibF5/\nPXIiD3iF3s5tA3jrYif0Rx0lYwEU/kIxtdAnBm6Evg0Ac7dTgbHMzHIAKsDrAgCNiagZESUBeA7A\nHYgUWug1ESArSzIePvWUpDgeNiyyx7/2Wsmz4jQTksqDZCf05oFVgBb62kCoom7uADCAiJYCGABg\nK4AKADcAmM3MfqfAJaKxRLSEiJbs2rWrZjXRQq+JAFlZMllERgbw/PORP/5xxwHXXee/jF00zY4d\nvm4bwH8GSy30iYGbqJutAI4xfc80llXCzNtgWPRE1AjAKGYuJKJ+AE4lohsANAJQl4gOMPMEy/av\nA3gdAHr37u0iAawftNBrIsDxx8v7yy/HbpCXXQbLHTuAPn18l/nLYKmmEdRRN/GNG6FfDCCLiNpD\nBP5iAH81FyCiDAB7mdkD4B4AUwGAmS81lbkSQG+ryIeUigpJ7qGFXhNm/vIXoFs3oEePaNfEGSeL\nXrtuah8BXTfMXA5gHICvAKwB8BEzryaih4noPKPYQABriWgdpOP1sTDV1z9Hjsi7FnpNmElJiW2R\nB6oK/YEDItxa6GsfrgZMMfNsALMty/5p+pwLIDfAPt4G8HbQNQyGWjKNoEbjhrQ0mQ1LoUIrtdDX\nPhIrBYIWeo2mEquP3knoU1Ml06adj14LfWKghV6jSVCsrhsnofc3+YjujE0MtNBrNAlKWhpQWuq9\nLZyEXpX157oJNL2eJrbRQq/RJChW3/uOHTKQqlkz+7JOQt+gQXxM7q5xJi6yV5aVlaGgoACHlZA7\nkZQEfPkl0KKFjEvXJDSpqanIzMxEnTp1ol2VmMQs9EcfLULfooWIvRW7mHtApyhOFOJC6AsKCtC4\ncWO0a9cORORcsLgYKC+XYYuNG0eugpqIw8zYs2cPCgoK0L59+2hXJyaxZrDcudPebQNIo6BcO2a0\n0CcGcfFAdvjwYTRr1sy/yAOSgg+Q3iVNQkNEaNasWeCnvFqMnevGmv7AXNapM1Z3xMY/cSH0AAKL\nPOBNqK0dirUCV9dELcZO6P1Z9E4+em3Rxz+JpYha6DWaSsxC7/EEdt3s3191Hlwt9IlBYilimFw3\ne/bsQU5ODnJyctCyZUu0adOm8ntpaamrfVx11VVYu3at3zIvvfQS3n///VBUWaPx8dHv2ydpoJyE\nXpUtLvZdroU+MYiLzljXhMmib9asGZYtWwYAePDBB9GoUSPccYdvin1mBjMjyeHYb731VsDj3Hjj\njTWvbIQpLy9HSkpiXUaJQqNGYvMUFfmPoQd8rf+mTb3LtdAnBvFn0Y8fDwwcaP86/3zg738Hhgxx\nLmP3Gj++WlXJz89HdnY2Lr30UnTr1g3bt2/H2LFj0bt3b3Tr1g0PP/xwZdlTTjkFy5YtQ3l5OdLT\n0zFhwgT06NED/fr1w59//gkAuO+++zBx4sTK8hMmTECfPn1w3HHH4YcffgAAlJSUYNSoUcjOzsaF\nF16I3r17VzZCZh544AGcdNJJOP7443HdddeBjaeddevWYdCgQejRowd69uyJzZs3AwAef/xxnHDC\nCejRowfuvfdenzoDwI4dO9DJmGj0jTfewPnnn4/TTz8dZ555JoqLizFo0CD07NkT3bt3x+dq1mpI\nA9e9e3f06NEDV111FYqKitChQweUl5cDAPbt2+fzXRM6kpJkpqlghd6M7oxNDOJP6N0QwU663377\nDbfeeivy8vLQpk0bPPnkk1iyZAmWL1+OOXPmIC8vr8o2RUVFGDBgAJYvX45+/fph6tSptvtmZvz8\n88945plnKhuNKVOmoGXLlsjLy8P999+PpUuX2m57yy23YPHixVi5ciWKiorw3//+FwBwySWX4NZb\nb8Xy5cvxww8/oEWLFvjss8/w5Zdf4ueff8by5ctx++23BzzvpUuX4uOPP8a8efNQv359fPLJJ/j1\n118xd+5c3HrrrQCA5cuX46mnnsLChQuxfPlyPPfcc0hLS0P//v0r6/PBBx/goosu0k8FYUJ1slZX\n6LVFnxjE391lWLy2bN0KbN8O9OoVMbHv2LEjevfuXfn9gw8+wJtvvony8nJs27YNeXl5yM7O9tmm\nfv36GD58OACgV69e+Pbbb233PXLkyMoyyvL+7rvvcPfddwMAevTogW7dutluO2/ePDzzzDM4fPgw\ndu/ejV69eqFv377YvXs3zj33XAAy4AgA5s6di6uvvhr1jXHuR7mYSWPo0KFoajzjMzMmTJiA7777\nDklJSdiyZQt2796N+fPnY/To0ZX7U+/XXHMNJk+ejHPOOQdvvfUW3n333YDH01SPtDTx0bsVeuug\nKS30iUH8Cb0/mOV5NYIWfUPTXbB+/XpMmjQJP//8M9LT0zFmzBjbOO+6detWfk5OTnZ0W9QzZnD2\nV8aOgwcPYty4cfj111/Rpk0b3HfffdWKN09JSYHH6Pewbm8+72nTpqGoqAi//vorUlJSkJmZ6fd4\nAwYMwLhx47BgwQLUqVMHXbp0CbpuGnekp3st+tRU5wnM7aYTrKiQKR600Mc/ieW68XiiOliquLgY\njRs3RpMmTbB9+3Z89dVXIT9G//798dFHHwEAVq5caesaOnToEJKSkpCRkYH9+/djxowZAICmTZui\nefPm+OyzzwCIeB88eBBnnHEGpk6dikOHDgEA9u7dCwBo164dfvnlFwBAbq7zdANFRUVo0aIFUlJS\nMGfOHGzdKjNNDho0CB9++GHl/tQ7AIwZMwaXXnoprrrqqhr9Hhr/mF03LVs63x52rhudojhxSDyh\nj2IMfc+ePZGdnY0uXbrg8ssvR//+/UN+jJtuuglbt25FdnY2HnroIWRnZyNN3aUGzZo1wxVXXIHs\n7GwMHz4cJ598cuW6999/H8899xy6d++OU045Bbt27cI555yDYcOGoXfv3sjJycELL7wAALjzzjsx\nadIk9OzZE/v27XOs02WXXYYffvgBJ5xwAqZPn46srCwA4lq66667cNpppyEnJwd33nln5TaXXnop\nioqKMHr06FD+PBoLVqH3Vw7wFXqdojiBUGGBsfLq1asXW8nLy6uyzJaNG5lXrHBXNk4pKyvjQ4cO\nMTPzunXruF27dlxWVhblWgXPBx98wFdeeWWN9+P62qil3HADc7NmzMcfz3z++f7LpqYy33mn93t+\nPjPA/M474a2jJjQAWMIOuurKR09EwwBMApAM4A1mftKyvi1kQvDmAPYCGMPMBcbymZAnhzoApjDz\nq6FrpixE2XUTCQ4cOIDBgwejvLwczIzXXnst7iJWrr/+esydO7cy8kYTPlRnLBEQ6AHTmsFSu24S\nh4AKQUTJAF4CcAaAAgCLiWgWM5udw88CmMbM7xDRIABPALgMwHYA/Zj5CBE1ArDK2HZbyM8EiLrr\nJhKkp6dX+s3jlVdeeSXaVag1pKdLp+ru3f5dN0DVfDda6BMHN6rYB0A+M29k5lIA0wGMsJTJBjDf\n+LxArWfmUmY+Yiyv5/J41Yc54S16jSYYzN03WuhrL26Etw2ALabvBcYyM8sBjDQ+XwCgMRE1AwAi\nOob+v727DY6qOgM4/n+EMOE1QkFEYjW1CpFN1iTkRZuEpBiHSgdK5C1iI2pwhqmkrXU6vg3aMvlQ\nRZo6Mo4IKsxUA6MiUoWOQzONfJAhiRIosdCRUELSNGDUaIZS7NMP9+66gWxeeHGzd5/fl+Tee/bu\nuSdnn9w999znijS4+/hdT2fzInK/iNSKSG17e/tAj+EbMXBGb8xAXEigt4ux3nGxouJDwAwR+RCY\nARwHvgZQ1WOqmgp8H7hbRM7JiK2q61R1uqpOnzBhwvnXIjCP3hgDDDzQ2xi9N/UnKh4Hrg5ZTnTX\nBalqi6oWq2oa8Ji77rOzywAHgLwLqnFvYuBirDEDEbgRCvoO9IGbqwIs0HtHfwL9XuB6EUkSkWHA\nYuDt0AIiMl5EAvt6BGcGDiKSKCLD3d/HArlA77l6L8QlGropLCw85+anyspKli9f3uvrRo0aBUBL\nSwvz58/vsUxBQQG1tbW97qeyspKuwPdo4Pbbb+eznh7wacxZQs/owz1dKrSsBXpv6jMqquoZ4AHg\nz0AjsEVV/yYivxWROW6xAuDvInIImAhUuOuTgT0isg/4K7BaVfdf5GMIrewlCfQlJSVUVVV1W1dV\nVUVJSUm/Xn/VVVf1emdpX84O9O+++y6Xh56qDXKqGkylYL5dgUCfkABuKqNey3Z1OXnrwQK9l/Qr\nKqrqu6p6g6pep6oV7rqVqvq2+/vrqnq9W6YsMNNGVd9T1VRV9bs/111ohXvLUlxw7/coWHzlgDIU\n9ydL8fz583nnnXeCDxlpamqipaWFvLy84Lz29PR0UlJS2LZt2zmvb2pqwufzAU56gsWLF5OcnMy8\nefOCaQfAmV8eSHH8xBNPAPDss8/S0tJCYWEhhYWFgJOa4MSJEwCsWbMGn8+Hz+cLpjhuamoiOTmZ\nZcuWMW3aNG677bZu7xOwfft2srOzSUtL49Zbb6WtrQ1w5urfc889pKSkkJqaGkyhsHPnTtLT0/H7\n/cycORNw8vOvXr06uE+fz0dTUxNNTU1MmTKF0tJSfD4fx44d6/H4APbu3cstt9yC3+8nKyuLzs5O\n8vPzu6Vfzs3NZd++fb3/ocw5AoG+r2Gb0LKBs/quLue8KSQ1k4lS0XWnTZ8ULsEQ/bhx48jKymLH\njh3MnTuXqqoqFi5ciIgQHx/P1q1bGTNmDCdOnCAnJ4c5c+aEfZ7p888/z4gRI2hsbKShoYH09PTg\ntoqKCsaNG8fXX3/NzJkzaWhooLy8nDVr1lBdXc348eO77auuro6XX36ZPXv2oKpkZ2czY8YMxo4d\ny+HDh3nttdd48cUXWbhwIW+88QZ33XVXt9fn5ubywQcfICKsX7+ep556imeeeYZVq1aRkJDA/v3O\nl6+Ojg7a29tZtmwZNTU1JCUldctbE87hw4fZuHEjOTk5YY9v6tSpLFq0iM2bN5OZmckXX3zB8OHD\nue+++3jllVeorKzk0KFDnDp1Cr/fP6C/m3HOxocMGXigHz/+m8yVdtkr+kVdoO8tSzF1h5yByMTE\ni/6+geGbQKDfsGED4AxLPProo9TU1HDZZZdx/Phx2trauDLMJ6umpoby8nIAUlNTSU1NDW7bsmUL\n69at48yZM7S2tnLw4MFu28+2e/du5s2bF8wkWVxczPvvv8+cOXNISkripptuArqnOQ7V3NzMokWL\naG1t5fTp0yQlJQFO2uLQoaqxY8eyfft28vPzg2X6k8r4mmuuCQb5cMcnIkyaNInMzEwAxrjpFRcs\nWMCqVat4+umneemll1i6dGmf72fOJeIE8P4E+sBo4KFDcN11lqLYS7wzF9FJy3HJplfOnTuXXbt2\nUV9fT1dXFxkZGYCTJKy9vZ26ujo++ugjJk6ceF4pgY8cOcLq1avZtWsXDQ0NzJ49+7z2ExBIcQzh\n0xyvWLGCBx54gP379/PCCy9ccCpj6J7OODSV8UCPb8SIERQVFbFt2za2bNnCkiVLBlw343jwQfjp\nT/sud/PNMHkyFBfDhg0W6L3EO4H+Ej0vNmDUqFEUFhZy7733drsIG0jRGxcXR3V1NUePHu11P/n5\n+bz66qsAHDhwgIaGBsBJcTxy5EgSEhJoa2tjx44dwdeMHj2azs7Oc/aVl5fHW2+9RVdXF1999RVb\nt24lL6//s1c///xzJk927n3buHFjcH1RURFr164NLnd0dJCTk0NNTQ1HjhwBuqcyrq+vB6C+vj64\n/Wzhjm/KlCm0trayd+9eADo7O4P/lMrKyigvLyczMzP4kBMzcI89BrNn913uiiugvh5yc6GsDLZu\ntUDvFd4J9O4zUS/lgGJJSQn79u3rFuiXLFlCbW0tKSkpbNq0qc+HaCxfvpwvv/yS5ORkVq5cGfxm\n4Pf7SUtLY+rUqdx5553dUhzff//9zJo1K3gxNiA9PZ2lS5eSlZVFdnY2ZWVlpKWl9ft4nnzySRYs\nWEBGRka38f/HH3+cjo4OfD4ffr+f6upqJkyYwLp16yguLsbv9wfTC99xxx18+umnTJs2jeeee44b\nbrihx/cKd3zDhg1j8+bNrFixAr/fT1FRUfBMPyMjgzFjxljO+m/RFVfAzp2wciWcOgWjR0e6RuZi\nEA0EyEFi+vTpeva88sbGRpKTk3t/4ZkzcPSocxXprPzsJjq1tLRQUFDAxx9/zGVhvqn1q2+Y87J7\nN8TFQcjjDMwgJiJ1qjq9p23eOaMfOtS5gmRB3hM2bdpEdnY2FRUVYYO8ubRycy3Ie0XUzboxsaG0\ntJTS0tJIV8MYT4iaU6XBNsRkIs/6hDH9ExWBPj4+npMnT9oH2wSpKidPniQ+Pj7SVTFm0IuKoZvE\nxESam5u5oFz1xnPi4+NJvAQ3xxnjNVER6OPi4oJ3ZBpjjBmYqBi6McYYc/4s0BtjjMdZoDfGGI8b\ndHfGikg70HvCmN6NB05cpOp4ibVLeNY24VnbhDfY2uYaVe3xoduDLtBfKBGpDXcbcCyzdgnP2iY8\na5vwoqltbOjGGGM8zgK9McZ4nBcD/QU/l9ajrF3Cs7YJz9omvKhpG8+N0RtjjOnOi2f0xhhjQlig\nN8YYj/NMoBeRWSLydxH5h4g8HOn6RJKIXC0i1SJyUET+JiI/d9ePE5H3ROSw+zMmH8QqIkNE5EMR\n+ZO7nCQie9y+s1lEhkW6jpEgIpeLyOsi8rGINIrIzdZnHCLyS/ezdEBEXhOR+GjqN54I9CIyBFgL\n/Ai4ESgRkRsjW6uIOgP8SlVvBHKAn7nt8TCwS1WvB3a5y7Ho50BjyPLvgN+r6veBDuC+iNQq8v4A\n7FTVqYAfp41ivs+IyGSgHJiuqj5gCLCYKOo3ngj0QBbwD1X9RFVPA1XA3AjXKWJUtVVV693fO3E+\nsJNx2mSjW2wj8JPI1DByRCQRmA2sd5cF+CHwulskVtslAcgHNgCo6mlV/QzrMwFDgeEiMhQYAbQS\nRf3GK4F+MnAsZLnZXRfzRORaIA3YA0xU1VZ307+AiRGqViRVAr8G/ucufwf4TFXPuMux2neSgHbg\nZXdYa72IjMT6DKp6HFgN/BMnwH8O1BFF/cYrgd70QERGAW8Av1DVL0K3qTOvNqbm1orIj4F/q2pd\npOsyCA0F0oHnVTUN+Iqzhmlisc8AuNcl5uL8M7wKGAnMimilBsgrgf44cHXIcqK7LmaJSBxOkP+j\nqr7prm4TkUnu9knAvyNVvwj5ATBHRJpwhvd+iDMufbn7lRxit+80A82qusddfh0n8Md6nwG4FTii\nqu2q+l/gTZy+FDX9xiuBfi9wvXsVfBjOhZK3I1yniHHHnTcAjaq6JmTT28Dd7u93A9u+7bpFkqo+\noqqJqnotTh/5i6ouAaqB+W6xmGsXAFX9F3BMRKa4q2YCB4nxPuP6J5AjIiPcz1agbaKm33jmzlgR\nuR1n/HUI8JKqVkS4ShEjIrnA+8B+vhmLfhRnnH4L8F2cVNALVfXTiFQywkSkAHhIVX8sIt/DOcMf\nB3wI3KWq/4lk/SJBRG7CuUg9DPgEuAfnZDDm+4yI/AZYhDOj7UOgDGdMPir6jWcCvTHGmJ55ZejG\nGGNMGBbojTHG4yzQG2OMx1mgN8YYj7NAb4wxHmeB3hhjPM4CvTHGeNz/AcZfuhNAHHrYAAAAAElF\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
